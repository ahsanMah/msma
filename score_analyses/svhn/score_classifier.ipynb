{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "PARENT_DIR = \"/home/Developer/NCSN-TF2.0/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "sys.path.append(PARENT_DIR)\n",
    "\n",
    "import PIL\n",
    "import utils, configs\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from helper import plot_confusion_matrix, metrics\n",
    "\n",
    "from datasets.dataset_loader import  *\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, average_precision_score\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from matplotlib.pyplot import imshow\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import umap\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "\n",
    "seed=42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood_detection_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = np.array([\"Train\", \"CIFAR\", \"CelebA\", \"SVHN\"])\n",
    "colors = [\"red\", \"blue\", \"green\", \"orange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resuming from latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images (InputLayer)             [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 128)  3584        images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "idx_sigmas (InputLayer)         [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conditional_full_pre_activation (None, 32, 32, 128)  302848      conv2d[0][0]                     \n",
      "                                                                 idx_sigmas[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conditional_full_pre_activation (None, 16, 16, 256)  929792      conditional_full_pre_activation_b\n",
      "                                                                 idx_sigmas[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conditional_full_pre_activation (None, 16, 16, 256)  1195520     conditional_full_pre_activation_b\n",
      "                                                                 idx_sigmas[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conditional_full_pre_activation (None, 16, 16, 256)  1195520     conditional_full_pre_activation_b\n",
      "                                                                 idx_sigmas[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "refine_block_3 (RefineBlock)    (None, 16, 16, 256)  4782080     conditional_full_pre_activation_b\n",
      "                                                                 idx_sigmas[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "refine_block_2 (RefineBlock)    (None, 16, 16, 256)  8368640     conditional_full_pre_activation_b\n",
      "                                                                 refine_block_3[0][0]             \n",
      "                                                                 idx_sigmas[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "refine_block_1 (RefineBlock)    (None, 16, 16, 256)  8368640     conditional_full_pre_activation_b\n",
      "                                                                 refine_block_2[0][0]             \n",
      "                                                                 idx_sigmas[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "refine_block (RefineBlock)      (None, 32, 32, 128)  2909824     conditional_full_pre_activation_b\n",
      "                                                                 refine_block_1[0][0]             \n",
      "                                                                 idx_sigmas[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conditional_instance_normalizat (None, 32, 32, 128)  3840        refine_block[0][0]               \n",
      "                                                                 idx_sigmas[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Elu (TensorFlowOpLa [(None, 32, 32, 128) 0           conditional_instance_normalizatio\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 3)    3459        tf_op_layer_Elu[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 28,063,747\n",
      "Trainable params: 28,063,747\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Trying to load latest model from /home/Developer/NCSN-TF2.0/saved_models/refinenet128_svhn_cropped_L10_SH1e+00_SL1e-02/train_test/\n",
      "Loaded model: /home/Developer/NCSN-TF2.0/saved_models/refinenet128_svhn_cropped_L10_SH1e+00_SL1e-02/train_test/ckpt-40\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(inlier_name=\"svhn_cropped\", save_path=PARENT_DIR+\"saved_models/\", checkpoint=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f1a81847510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function <lambda> at 0x7f1a81847510>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f1a81847510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function <lambda> at 0x7f1a81847510>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f1a81847510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function <lambda> at 0x7f1a81847510>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "CPU times: user 4min 13s, sys: 2min 54s, total: 7min 8s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "TEST_BATCH = 1000\n",
    "svhn_train_batches = []\n",
    "\n",
    "with tf.device('CPU'):\n",
    "    data_generators = tfds.load(name=\"svhn_cropped\", batch_size=-1, data_dir=PARENT_DIR+\"data\", shuffle_files=True)\n",
    "    svhn_train = tf.data.Dataset.from_tensor_slices(data_generators['train'][\"image\"]).take(73000)\n",
    "    svhn_train = svhn_train.map(lambda x: x/255, num_parallel_calls=AUTOTUNE)\n",
    "    svhn_train = svhn_train.batch(TEST_BATCH)\n",
    "    \n",
    "svhn_train_batches = [x for x in svhn_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_score_norms(model, x_test):\n",
    "    \n",
    "#     # Sigma Idx -> Score\n",
    "#     norm_batches = []\n",
    "    \n",
    "#     sigmas = utils.get_sigma_levels().numpy()\n",
    "#     final_logits = 0 #tf.zeros(logits_shape)\n",
    "#     progress_bar = tqdm(x_test)\n",
    "    \n",
    "#     for x_batch in x_test:\n",
    "# #         progress_bar.set_description(\"Sigma: {:.4f}\".format(sigma))\n",
    "#         _logits = []\n",
    "#         for idx, sigma in enumerate(sigmas):\n",
    "#             idx_sigmas = tf.ones(x_batch.shape[0], dtype=tf.int32) * idx\n",
    "#             score = model([x_batch, idx_sigmas])\n",
    "#             _logits.append(score)\n",
    "\n",
    "#         _logits = tf.concat(_logits, axis=0)\n",
    "#         norm_batches.append(weighted_norm(_logits))\n",
    "#         del _logits\n",
    "\n",
    "#     return norm_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sigma: 0.0100: 100%|██████████| 10/10 [22:35<00:00, 135.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 47s, sys: 5min 51s, total: 12min 38s\n",
      "Wall time: 22min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svhn_train_scores = compute_scores(model, svhn_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_train_norms = weighted_norm(svhn_train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([73000, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svhn_train_norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"train_scores_ckpt-last.p\", \"wb\") as f:\n",
    "    pickle.dump(svhn_train_norms.numpy(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
